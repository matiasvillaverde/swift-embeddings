import Command
import CoreML
import Testing
import TestingUtils

@testable import Embeddings

/*
 NOTE:
 The following test are testing the accuracy of the embeddings generated by the Swift models
 against the embeddings generated by the Python transformers library. They they are slow
 and require the [uv](https://github.com/astral-sh/uv) command line tool to be available.

 This suite can be run using the following command from the command line:

 ```
 PYTORCH_ENABLE_MPS_FALLBACK=1 UV_PATH=$(which uv) swift test --filter AccuracyTests
 ```

*/

func generateUsingTransformers(
    modelPath: String,
    text: String,
    modelType: ModelType
) async throws -> [Float] {
    let scriptUrl = try #require(
        Bundle.module.path(forResource: "generate", ofType: "py", inDirectory: "Scripts"),
        "Script not found"
    )
    let uvPath = try #require(ProcessInfo.processInfo.environment["UV_PATH"], "UV_PATH not found")
    let arguments = [uvPath, "run", scriptUrl, modelPath, text, modelType.rawValue]
    let result =
        try await Command
        .run(arguments: arguments)
        .concatenatedString()
    return
        result
        .components(separatedBy: .newlines)
        .filter { !$0.isEmpty }
        .map { stringValue -> Float in
            guard let value = Float(stringValue) else {
                fatalError("Invalid float value in stdout: \(stringValue)")
            }
            return value
        }
}

func modelPath(modelId: String, cacheDirectory: URL) -> String {
    cacheDirectory
        .appendingPathComponent("models")
        .appendingPathComponent(modelId)
        .path()
}

enum ModelType: String {
    case bert
    case clip
    case model2Vec = "model2vec"
    case staticEmbeddings = "static-embeddings"
    case xlmRoberta = "xlm-roberta"
}

@Suite struct AccuracyTests {
    let cacheDirectory = FileManager.default.temporaryDirectory

    @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, watchOS 11.0, *)
    @Test(
        "Bert Accuracy",
        .enabled(if: ProcessInfo.processInfo.environment["UV_PATH"] != nil),
        arguments: ["Text to encode", "", "❤️"]
    )
    func bertAccuracy(_ text: String) async throws {
        let modelId = "google-bert/bert-base-uncased"
        let modelBundle = try await Bert.loadModelBundle(
            from: modelId,
            downloadBase: cacheDirectory,
            loadConfig: LoadConfig.googleBert
        )
        let encoded = try modelBundle.encode(text)
        let swiftData = await encoded.cast(to: Float.self).scalars(of: Float.self)
        let modelPath = modelPath(modelId: modelId, cacheDirectory: cacheDirectory)
        let pythonData = try await generateUsingTransformers(
            modelPath: modelPath,
            text: text,
            modelType: .bert
        )

        #expect(allClose(pythonData, swiftData, absoluteTolerance: 1e-5) == true)
    }

    @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, watchOS 11.0, *)
    @Test(
        "Clip Accuracy",
        .enabled(if: ProcessInfo.processInfo.environment["UV_PATH"] != nil)
    )
    func clipAccuracy() async throws {
        let text = "a photo of a dog"
        let modelId = "jkrukowski/clip-vit-base-patch32"
        let modelBundle = try await Clip.loadModelBundle(
            from: modelId,
            downloadBase: cacheDirectory
        )
        let tokens = try modelBundle.tokenizer.tokenizeText(text, maxLength: 77)
        let inputIds = MLTensor(shape: [1, tokens.count], scalars: tokens)
        let modelOutput = modelBundle.textModel(inputIds: inputIds)
        let swiftData =
            await modelOutput
            .poolerOutput
            .cast(to: Float.self)
            .scalars(of: Float.self)
        let modelPath = modelPath(modelId: modelId, cacheDirectory: cacheDirectory)
        let pythonData = try await generateUsingTransformers(
            modelPath: modelPath,
            text: text,
            modelType: .clip
        )

        #expect(allClose(pythonData, swiftData, absoluteTolerance: 1e-5) == true)
    }

    @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, watchOS 11.0, *)
    @Test(
        "XLM Roberta Accuracy",
        .enabled(if: ProcessInfo.processInfo.environment["UV_PATH"] != nil),
        arguments: ["Text to encode", "", "❤️"]
    )
    func xlmRobertaAccuracy(_ text: String) async throws {
        let modelId = "tomaarsen/xlm-roberta-base-multilingual-en-ar-fr-de-es-tr-it"
        let modelBundle = try await XLMRoberta.loadModelBundle(
            from: modelId,
            downloadBase: cacheDirectory
        )
        let encoded = try modelBundle.encode(text)
        let swiftData = await encoded.cast(to: Float.self).scalars(of: Float.self)
        let modelPath = modelPath(modelId: modelId, cacheDirectory: cacheDirectory)
        let pythonData = try await generateUsingTransformers(
            modelPath: modelPath,
            text: text,
            modelType: .xlmRoberta
        )

        #expect(allClose(pythonData, swiftData, absoluteTolerance: 1e-5) == true)
    }

    @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, watchOS 11.0, *)
    @Test(
        "Model2Vec Accuracy",
        .enabled(if: ProcessInfo.processInfo.environment["UV_PATH"] != nil),
        arguments: ["Text to encode", "", "❤️"]
    )
    func model2VecAccuracy(_ text: String) async throws {
        let modelId = "minishlab/potion-base-2M"
        let modelBundle = try await Model2Vec.loadModelBundle(
            from: modelId,
            downloadBase: cacheDirectory
        )
        let encoded = try modelBundle.encode(text, normalize: modelBundle.model.normalize)
        let swiftData = await encoded.cast(to: Float.self).scalars(of: Float.self)
        let modelPath = modelPath(modelId: modelId, cacheDirectory: cacheDirectory)
        let pythonData = try await generateUsingTransformers(
            modelPath: modelPath,
            text: text,
            modelType: .model2Vec
        )

        #expect(allClose(pythonData, swiftData, absoluteTolerance: 1e-5) == true)
    }

    @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, watchOS 11.0, *)
    @Test(
        "Static Embeddings Accuracy",
        .enabled(if: ProcessInfo.processInfo.environment["UV_PATH"] != nil),
        arguments: ["Text to encode", "", "❤️"]
    )
    func staticEmbeddingsAccuracy(_ text: String) async throws {
        let modelId = "sentence-transformers/static-retrieval-mrl-en-v1"
        let modelBundle = try await StaticEmbeddings.loadModelBundle(
            from: modelId,
            downloadBase: cacheDirectory,
            loadConfig: LoadConfig.staticEmbeddings
        )
        let encoded = try modelBundle.encode(text, normalize: true, truncateDimension: 1023)
        let swiftData = await encoded.cast(to: Float.self).scalars(of: Float.self)
        let modelPath = modelPath(modelId: modelId, cacheDirectory: cacheDirectory)
        let pythonData = try await generateUsingTransformers(
            modelPath: modelPath,
            text: text,
            modelType: .staticEmbeddings
        )

        #expect(allClose(pythonData, swiftData, absoluteTolerance: 1e-5) == true)
    }
}
